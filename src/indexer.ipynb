{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting faiss-cpu\n",
      "  Downloading faiss_cpu-1.8.0.post1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: numpy<2.0,>=1.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from faiss-cpu) (1.26.4)\n",
      "Requirement already satisfied: packaging in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from faiss-cpu) (23.2)\n",
      "Downloading faiss_cpu-1.8.0.post1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (27.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.0/27.0 MB\u001b[0m \u001b[31m112.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: faiss-cpu\n",
      "Successfully installed faiss-cpu-1.8.0.post1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:root:loading pretrained model colbert-ir/colbertv2.0...\n",
      "[Aug 05, 22:11:19] Loading segmented_maxsim_cpp extension (set COLBERT_LOAD_TORCH_EXTENSION_VERBOSE=True for more info)...\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/colbert/utils/amp.py:12: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler()\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/amp/grad_scaler.py:132: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "INFO:root:pretrained model colbert-ir/colbertv2.0 loaded.\n",
      "INFO:root:git repo psf/requests cloned.\n",
      "---- WARNING! You are using PLAID with an experimental replacement for FAISS for greater compatibility ----\n",
      "This is a behaviour change from RAGatouille 0.8.0 onwards.\n",
      "This works fine for most users and smallish datasets, but can be considerably slower than FAISS and could cause worse results in some situations.\n",
      "If you're confident with FAISS working on your machine, pass use_faiss=True to revert to the FAISS-using behaviour.\n",
      "--------------------\n",
      "\n",
      "\n",
      "[Aug 05, 22:11:19] #> Note: Output directory .ragatouille/colbert/indexes/requests already exists\n",
      "\n",
      "\n",
      "[Aug 05, 22:11:19] #> Will delete 11 files already at .ragatouille/colbert/indexes/requests in 20 seconds...\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/colbert/utils/amp.py:12: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler()\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/amp/grad_scaler.py:132: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "[Aug 05, 22:11:40] [0] \t\t #> Encoding 158 passages..\n",
      "  0%|                                                     | 0/5 [00:00<?, ?it/s]/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/colbert/utils/amp.py:15: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  return torch.cuda.amp.autocast() if self.activated else NullContextManager()\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/amp/autocast_mode.py:265: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "100%|█████████████████████████████████████████████| 5/5 [00:12<00:00,  2.52s/it]\n",
      "[Aug 05, 22:11:52] [0] \t\t avg_doclen_est = 271.47467041015625 \t len(local_sample) = 158\n",
      "[Aug 05, 22:11:52] [0] \t\t Creating 2,048 partitions.\n",
      "[Aug 05, 22:11:52] [0] \t\t *Estimated* 42,892 embeddings.\n",
      "[Aug 05, 22:11:52] [0] \t\t #> Saving the indexing plan to .ragatouille/colbert/indexes/requests/plan.json ..\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/colbert/indexing/collection_indexer.py:256: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  sub_sample = torch.load(sub_sample_path)\n",
      "used 20 iterations (2.8072s) to cluster 40749 items into 2048 clusters\n",
      "[0.028, 0.029, 0.029, 0.025, 0.026, 0.028, 0.026, 0.027, 0.028, 0.028, 0.026, 0.028, 0.027, 0.028, 0.027, 0.028, 0.026, 0.028, 0.028, 0.027, 0.027, 0.028, 0.028, 0.027, 0.025, 0.028, 0.028, 0.028, 0.028, 0.028, 0.028, 0.029, 0.028, 0.026, 0.028, 0.025, 0.028, 0.028, 0.025, 0.033, 0.029, 0.028, 0.028, 0.03, 0.027, 0.027, 0.025, 0.032, 0.03, 0.031, 0.026, 0.027, 0.029, 0.027, 0.027, 0.03, 0.03, 0.028, 0.031, 0.026, 0.028, 0.029, 0.027, 0.029, 0.027, 0.029, 0.027, 0.027, 0.027, 0.028, 0.028, 0.026, 0.027, 0.028, 0.027, 0.029, 0.027, 0.027, 0.028, 0.032, 0.028, 0.03, 0.028, 0.028, 0.028, 0.027, 0.027, 0.029, 0.025, 0.033, 0.026, 0.028, 0.025, 0.029, 0.028, 0.026, 0.031, 0.028, 0.03, 0.027, 0.026, 0.031, 0.03, 0.027, 0.027, 0.028, 0.027, 0.026, 0.028, 0.025, 0.028, 0.028, 0.028, 0.028, 0.028, 0.027, 0.029, 0.029, 0.027, 0.029, 0.025, 0.027, 0.027, 0.032, 0.028, 0.031, 0.028, 0.026]\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/colbert/indexing/codecs/residual.py:141: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  centroids = torch.load(centroids_path, map_location='cpu')\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/colbert/indexing/codecs/residual.py:142: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  avg_residual = torch.load(avgresidual_path, map_location='cpu')\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/colbert/indexing/codecs/residual.py:143: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  bucket_cutoffs, bucket_weights = torch.load(buckets_path, map_location='cpu')\n",
      "0it [00:00, ?it/s][Aug 05, 22:11:55] [0] \t\t #> Encoding 158 passages..\n",
      "\n",
      "  0%|                                                     | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      " 20%|█████████                                    | 1/5 [00:02<00:10,  2.55s/it]\u001b[A\n",
      " 40%|██████████████████                           | 2/5 [00:04<00:07,  2.45s/it]\u001b[A\n",
      " 60%|███████████████████████████                  | 3/5 [00:07<00:04,  2.44s/it]\u001b[A\n",
      " 80%|████████████████████████████████████         | 4/5 [00:09<00:02,  2.41s/it]\u001b[A\n",
      "100%|█████████████████████████████████████████████| 5/5 [00:11<00:00,  2.40s/it]\u001b[A\n",
      "1it [00:12, 12.21s/it]\n",
      "  0%|                                                     | 0/1 [00:00<?, ?it/s]/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/colbert/indexing/codecs/residual_embeddings.py:86: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(codes_path, map_location='cpu')\n",
      "100%|███████████████████████████████████████████| 1/1 [00:00<00:00, 1732.47it/s]\n",
      "[Aug 05, 22:12:07] #> Optimizing IVF to store map from centroids to list of pids..\n",
      "[Aug 05, 22:12:07] #> Building the emb2pid mapping..\n",
      "[Aug 05, 22:12:07] len(emb2pid) = 42893\n",
      "100%|████████████████████████████████████| 2048/2048 [00:00<00:00, 79857.34it/s]\n",
      "[Aug 05, 22:12:08] #> Saved optimized IVF to .ragatouille/colbert/indexes/requests/ivf.pid.pt\n",
      "Done indexing!\n",
      "INFO:root:created index in .ragatouille/colbert/indexes/requests\n"
     ]
    }
   ],
   "source": [
    "!python colbert-rag/src/indexer.py --name requests --repo_name psf/requests --chunk_size=512"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
